{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/6U6q5jQ.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Collection in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='beginning'></a>\n",
    "This session pays attention to get data. In this situation, you can be confronted with a decision to collect data from repositories or similar sources, or collect your own data to answer an ad-hoc research question. The latter case will make you consider if you need a probabilistic or non-probabilistic design; which will also determine the next steps in your design.\n",
    "In any case, you need to collect data to be read by R or Python, unless your data is not suitable for any kind of computational data processing. But in this unit, I am assuming it is. If you have collected your data, a popular choice to record your observations is an spreadsheet, maybe using Excel or GoogleDocs. If you have collected data from another party, you may also have spreadsheets, or more sophisticated files in particular formats, like SPSS or STATA. Maybe you decided to collect data from the web, and you may be dealing with XML or JSON formats; or simply text without much structure. Let me show you how to deal with the following cases:\n",
    "\n",
    "1. [Propietary software.](#part1) \n",
    "2. [Ad-hoc collection.](#part2) \n",
    "3. [Use of APIs.](#part3) \n",
    "4. [Scraping webpages.](#part4) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the location of your files is extremely important. If you have created a folder name \"my project\", your code should be in that folder, which I call sometimes the root folder,  and your data in another folder inside that root folder. In any case, you should become familiar with some important commands from the **os** package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two more important uses are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\Documents\\\\GitHub\\\\Data-Collection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where am I?\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file is in a folder inside your root folder, you simply write: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder=\"data\"\n",
    "fileName=\"anes_timeseries_2012.dta\"\n",
    "fileToRead=os.path.join(folder,fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object _fileToRead_ has the right name of the path, because **os.path.join** creates a path using the elements between the parenthesis. Notice that if you are using Windows, a folder in \"C\" hard drive should be written like this: \n",
    "os.path.join('c:/','folder1', 'folder2'). Notice that you can write several folders, and path.join creates the right separator, but just for Windows you need that element ':/'. If you want to know the separator your computer is using, type this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn our attention to the file acquisition process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____\n",
    "\n",
    "\n",
    "<a id='part1'></a>\n",
    "## Collecting data from propietary software\n",
    "\n",
    "Let's start with data from SPSS and STATA, very common in public policy schools. To work with these kind of files, we will simply use *pandas*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____\n",
    "\n",
    "\n",
    "<a id='part1'></a>\n",
    "## Collecting data from propietary software\n",
    "\n",
    "Let's start with data from SPSS and STATA, very common in public policy schools. To work with these kind of files, we will simply use *pandas*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-15.0.0-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pyarrow) (1.26.4)\n",
      "Downloading pyarrow-15.0.0-cp311-cp311-win_amd64.whl (24.8 MB)\n",
      "   ---------------------------------------- 0.0/24.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.8 MB 435.7 kB/s eta 0:00:57\n",
      "   ---------------------------------------- 0.2/24.8 MB 1.7 MB/s eta 0:00:15\n",
      "    --------------------------------------- 0.6/24.8 MB 4.3 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.0/24.8 MB 5.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.3/24.8 MB 5.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.7/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.1/24.8 MB 6.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.3/24.8 MB 6.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.6/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.8/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.1/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.5/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 3.8/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.0/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.3/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.5/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.7/24.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.8/24.8 MB 5.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.9/24.8 MB 5.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.0/24.8 MB 5.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.1/24.8 MB 5.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.3/24.8 MB 5.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.4/24.8 MB 5.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.6/24.8 MB 4.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.7/24.8 MB 4.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.8/24.8 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.9/24.8 MB 4.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.9/24.8 MB 4.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.0/24.8 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.1/24.8 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.1/24.8 MB 4.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.2/24.8 MB 4.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.3/24.8 MB 4.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.3/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.5/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.7/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 6.9/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.1/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.3/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.4/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.6/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.8/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 8.0/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.1/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.4/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.6/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 8.8/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.0/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.2/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.5/24.8 MB 4.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.7/24.8 MB 4.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.8/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 9.9/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.1/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.3/24.8 MB 4.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.5/24.8 MB 4.1 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.7/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.9/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 11.0/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.2/24.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.4/24.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.5/24.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.7/24.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.9/24.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.0/24.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.2/24.8 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.4/24.8 MB 3.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.5/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.7/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.8/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.9/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.1/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.2/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.3/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.5/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.7/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.9/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.1/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.2/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.4/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.5/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.7/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.9/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.1/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.3/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.6/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.8/24.8 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 16.0/24.8 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.3/24.8 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.5/24.8 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.8/24.8 MB 4.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 17.1/24.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.4/24.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.7/24.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.9/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.1/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.3/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.5/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.7/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.0/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.2/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.3/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.5/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.7/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.9/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.1/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.2/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.4/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.7/24.8 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.0/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.2/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.4/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.5/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.7/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.9/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.0/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.2/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.3/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.4/24.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.7/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.8/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.5/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.9/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.1/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.2/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.7/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.8/24.8 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-15.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I using a file from the American National Election Studies (ANES). This is a rather big file, so let me select some variables (\"libcpre_self\",\"libcpo_self\",a couple of question pre and post elections asking respondents to place themselves on a seven point scale ranging from ‘extremely liberal’ to ‘extremely conservative’) and create a data frame with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsOfInterest=[\"libcpre_self\",\"libcpo_self\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a Stata file into pandas is quite easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder=\"data\"\n",
    "fileName=\"anes_timeseries_2012.dta\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "dataStata=pd.read_stata(fileToRead,columns=varsOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>libcpre_self</th>\n",
       "      <th>libcpo_self</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Extremely liberal</td>\n",
       "      <td>-6. Not asked, unit nonresponse (no post-elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. Extremely liberal</td>\n",
       "      <td>2. Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2. Haven't thought much about this</td>\n",
       "      <td>2. Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2. Haven't thought much about this</td>\n",
       "      <td>-8. Don't know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2. Liberal</td>\n",
       "      <td>2. Liberal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          libcpre_self  \\\n",
       "0                 1. Extremely liberal   \n",
       "1                 1. Extremely liberal   \n",
       "2  -2. Haven't thought much about this   \n",
       "3  -2. Haven't thought much about this   \n",
       "4                           2. Liberal   \n",
       "\n",
       "                                         libcpo_self  \n",
       "0  -6. Not asked, unit nonresponse (no post-elect...  \n",
       "1                                         2. Liberal  \n",
       "2                                         2. Liberal  \n",
       "3                                     -8. Don't know  \n",
       "4                                         2. Liberal  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataStata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening SPSS files in pandas requires you previously install pyreadstat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: pyreadstat\n"
     ]
    }
   ],
   "source": [
    "# do you have it?\n",
    "!pip show pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyreadstat'.  Use pip or conda to install pyreadstat.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyreadstat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m fileToRead\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder,fileName)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Open it: \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dataSpss\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_spss(fileToRead)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\site-packages\\pandas\\io\\spss.py:58\u001b[0m, in \u001b[0;36mread_spss\u001b[1;34m(path, usecols, convert_categoricals, dtype_backend)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_spss\u001b[39m(\n\u001b[0;32m     23\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path,\n\u001b[0;32m     24\u001b[0m     usecols: Sequence[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m     convert_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     26\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m     27\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Load an SPSS file from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    >>> df = pd.read_spss(\"spss_data.sav\")  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     pyreadstat \u001b[38;5;241m=\u001b[39m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyreadstat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m     check_dtype_backend(dtype_backend)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m usecols \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pyreadstat'.  Use pip or conda to install pyreadstat."
     ]
    }
   ],
   "source": [
    "# Set up the file location:\n",
    "fileName=\"anes_timeseries_2012.sav\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "\n",
    "# Open it: \n",
    "dataSpss=pd.read_spss(fileToRead) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSpss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the file location:\n",
    "fileName=\"HDI.xlsx\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "\n",
    "# Open it: \n",
    "dataExcel=pd.read_excel(fileToRead) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExcel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "_____\n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "## Collecting your ad-hoc data\n",
    "\n",
    "Let me assume you have collected some data using Google Forms. The answers to your form are saved in an spreadsheet, which you should publish as a CSV file. Then, I can read it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "link='https://docs.google.com/spreadsheets/d/e/2PACX-1vRCHCDPx4NmYA5phchO2rZhZSPvHZjkF08E11i3gsjHCy4zVWc12IRGg8rMzDgpvIHCZQqGeqPFhWa6/pub?gid=692075096&single=true&output=csv'\n",
    "fromGoogle = pd.read_csv(link)\n",
    "\n",
    "# here it is:\n",
    "fromGoogle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromGoogle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "-----\n",
    "\n",
    "<a id='part3'></a>\n",
    "\n",
    "## Collecting data from APIs\n",
    "\n",
    "There are organizations, public and private, that have an open data policy that allows people to access their repositories dynamically. You can get that data in CSV format if available, but the data is always in  XML or JSON format, which are containers that store data in an *associative array* structure. Python's dictionaries are very useful in these situations, as they can keep the NOSQL structure better than data frames. Let me get the data about 9-1-1 Police reponses from Seattle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sodapy\n",
    "\n",
    "# make sure to install these packages before running:\n",
    "# pip install pandas\n",
    "# pip install sodapy\n",
    "\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "client = Socrata(\"data.seattle.gov\", None)\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "# client = Socrata(data.seattle.gov,\n",
    "#                  MyAppToken,\n",
    "#                  username=\"user@example.com\",\n",
    "#                  password=\"AFakePassword\")\n",
    "\n",
    "# First 2000 results, returned as JSON from API / converted to Python list of\n",
    "# dictionaries by sodapy.\n",
    "results = client.get(\"kzjm-xkqj\", limit=2000)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "results_df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "_____\n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "## Collecting data by scraping\n",
    "\n",
    "We are going to get the data from a table from this [wikipage](https://en.wikipedia.org/wiki/List_of_freedom_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show beautifulsoup4 html5lib lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Location \n",
    "wikilink = \"https://en.wikipedia.org/wiki/List_of_freedom_indices\" \n",
    "\n",
    "wikiTables1=pd.read_html(wikilink)\n",
    "wikiTables2=pd.read_html(wikilink,attrs={'class':'wikitable sortable'})\n",
    "wikiTables3=pd.read_html(wikilink,match=\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many are there?\n",
    "len(wikiTables1),len(wikiTables2),len(wikiTables3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2_bs=pd.read_html(wikilink,flavor='bs4',\n",
    "                            attrs={'class':'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2_bs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2_bs[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freedomDF=wikiTables2_bs[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
