{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/6U6q5jQ.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Collection in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='beginning'></a>\n",
    "This session pays attention to get data. In this situation, you can be confronted with a decision to collect data from repositories or similar sources, or collect your own data to answer an ad-hoc research question. The latter case will make you consider if you need a probabilistic or non-probabilistic design; which will also determine the next steps in your design.\n",
    "In any case, you need to collect data to be read by R or Python, unless your data is not suitable for any kind of computational data processing. But in this unit, I am assuming it is. If you have collected your data, a popular choice to record your observations is an spreadsheet, maybe using Excel or GoogleDocs. If you have collected data from another party, you may also have spreadsheets, or more sophisticated files in particular formats, like SPSS or STATA. Maybe you decided to collect data from the web, and you may be dealing with XML or JSON formats; or simply text without much structure. Let me show you how to deal with the following cases:\n",
    "\n",
    "1. [Propietary software.](#part1) \n",
    "2. [Ad-hoc collection.](#part2) \n",
    "3. [Use of APIs.](#part3) \n",
    "4. [Scraping webpages.](#part4) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the location of your files is extremely important. If you have created a folder name \"my project\", your code should be in that folder, which I call sometimes the root folder,  and your data in another folder inside that root folder. In any case, you should become familiar with some important commands from the **os** package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two more important uses are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\Documents\\\\GitHub\\\\Data-Collection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where am I?\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file is in a folder inside your root folder, you simply write: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder=\"data\"\n",
    "fileName=\"anes_timeseries_2012.dta\"\n",
    "fileToRead=os.path.join(folder,fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object _fileToRead_ has the right name of the path, because **os.path.join** creates a path using the elements between the parenthesis. Notice that if you are using Windows, a folder in \"C\" hard drive should be written like this: \n",
    "os.path.join('c:/','folder1', 'folder2'). Notice that you can write several folders, and path.join creates the right separator, but just for Windows you need that element ':/'. If you want to know the separator your computer is using, type this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn our attention to the file acquisition process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____\n",
    "\n",
    "\n",
    "<a id='part1'></a>\n",
    "## Collecting data from propietary software\n",
    "\n",
    "Let's start with data from SPSS and STATA, very common in public policy schools. To work with these kind of files, we will simply use *pandas*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____\n",
    "\n",
    "\n",
    "<a id='part1'></a>\n",
    "## Collecting data from propietary software\n",
    "\n",
    "Let's start with data from SPSS and STATA, very common in public policy schools. To work with these kind of files, we will simply use *pandas*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-15.0.0-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in c:\\users\\dell\\anaconda3\\envs\\pythonr\\lib\\site-packages (from pyarrow) (1.26.4)\n",
      "Downloading pyarrow-15.0.0-cp311-cp311-win_amd64.whl (24.8 MB)\n",
      "   ---------------------------------------- 0.0/24.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.8 MB 435.7 kB/s eta 0:00:57\n",
      "   ---------------------------------------- 0.2/24.8 MB 1.7 MB/s eta 0:00:15\n",
      "    --------------------------------------- 0.6/24.8 MB 4.3 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.0/24.8 MB 5.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.3/24.8 MB 5.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.7/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.1/24.8 MB 6.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.3/24.8 MB 6.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.6/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.8/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.1/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.5/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 3.8/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.0/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.3/24.8 MB 6.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.5/24.8 MB 6.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.7/24.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.8/24.8 MB 5.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.9/24.8 MB 5.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.0/24.8 MB 5.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.1/24.8 MB 5.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.3/24.8 MB 5.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.4/24.8 MB 5.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.6/24.8 MB 4.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.7/24.8 MB 4.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.8/24.8 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.9/24.8 MB 4.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.9/24.8 MB 4.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.0/24.8 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.1/24.8 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.1/24.8 MB 4.3 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.2/24.8 MB 4.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.3/24.8 MB 4.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.3/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.5/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.7/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 6.9/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.1/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.3/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.4/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.6/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.8/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 8.0/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.1/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.4/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.6/24.8 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 8.8/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.0/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.2/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.5/24.8 MB 4.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.7/24.8 MB 4.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.8/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 9.9/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.1/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.3/24.8 MB 4.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.5/24.8 MB 4.1 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.7/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.9/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 11.0/24.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.2/24.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.4/24.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.5/24.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.7/24.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.9/24.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.0/24.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.2/24.8 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.4/24.8 MB 3.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.5/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.7/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.8/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.9/24.8 MB 3.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.1/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.2/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.3/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.5/24.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.7/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.9/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.1/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.2/24.8 MB 3.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.4/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.5/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.7/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.9/24.8 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.1/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.3/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.6/24.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.8/24.8 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 16.0/24.8 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.3/24.8 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.5/24.8 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.8/24.8 MB 4.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 17.1/24.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.4/24.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.7/24.8 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.9/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.1/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.3/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.5/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.7/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.0/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.2/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.3/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.5/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.7/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.9/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.1/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.2/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.4/24.8 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.7/24.8 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.0/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.2/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.4/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.5/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.7/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.9/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.0/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.2/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.3/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.4/24.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.7/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.8/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.5/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.9/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.1/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.2/24.8 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.7/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.8/24.8 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-15.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I using a file from the American National Election Studies (ANES). This is a rather big file, so let me select some variables (\"libcpre_self\",\"libcpo_self\",a couple of question pre and post elections asking respondents to place themselves on a seven point scale ranging from ‘extremely liberal’ to ‘extremely conservative’) and create a data frame with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsOfInterest=[\"libcpre_self\",\"libcpo_self\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a Stata file into pandas is quite easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\anes_timeseries_2012.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m fileName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manes_timeseries_2012.dta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m fileToRead\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder,fileName)\n\u001b[1;32m----> 5\u001b[0m dataStata\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_stata(fileToRead,columns\u001b[38;5;241m=\u001b[39mvarsOfInterest)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\site-packages\\pandas\\io\\stata.py:2109\u001b[0m, in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[0;32m   2106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[1;32m-> 2109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\site-packages\\pandas\\io\\stata.py:1683\u001b[0m, in \u001b[0;36mStataReader.read\u001b[1;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_method_doc)\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m   1673\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1681\u001b[0m     order_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1682\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 1683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_open()\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# Handle options\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\site-packages\\pandas\\io\\stata.py:1175\u001b[0m, in \u001b[0;36mStataReader._ensure_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;124;03mEnsure the file has been opened and its header data read.\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_path_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_file()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\site-packages\\pandas\\io\\stata.py:1188\u001b[0m, in \u001b[0;36mStataReader._open_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entered:\n\u001b[0;32m   1182\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStataReader is being used without using a context manager. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing StataReader as a context manager is the only supported method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;167;01mResourceWarning\u001b[39;00m,\n\u001b[0;32m   1186\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1187\u001b[0m     )\n\u001b[1;32m-> 1188\u001b[0m handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_path_or_buf,\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1191\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_options,\n\u001b[0;32m   1192\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1193\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression,\n\u001b[0;32m   1194\u001b[0m )\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;66;03m# If the handle is directly seekable, use it without an extra copy.\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonR\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\anes_timeseries_2012.dta'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "folder=\"data\"\n",
    "fileName=\"anes_timeseries_2012.dta\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "dataStata=pd.read_stata(fileToRead,columns=varsOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening SPSS files in pandas requires you previously install pyreadstat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: pyreadstat\n"
     ]
    }
   ],
   "source": [
    "# do you have it?\n",
    "!pip show pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the file location:\n",
    "fileName=\"anes_timeseries_2012.sav\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "\n",
    "# Open it: \n",
    "dataSpss=pd.read_spss(fileToRead) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSpss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the file location:\n",
    "fileName=\"HDI.xlsx\"\n",
    "fileToRead=os.path.join(folder,fileName)\n",
    "\n",
    "# Open it: \n",
    "dataExcel=pd.read_excel(fileToRead) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExcel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "_____\n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "## Collecting your ad-hoc data\n",
    "\n",
    "Let me assume you have collected some data using Google Forms. The answers to your form are saved in an spreadsheet, which you should publish as a CSV file. Then, I can read it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "link='https://docs.google.com/spreadsheets/d/e/2PACX-1vRCHCDPx4NmYA5phchO2rZhZSPvHZjkF08E11i3gsjHCy4zVWc12IRGg8rMzDgpvIHCZQqGeqPFhWa6/pub?gid=692075096&single=true&output=csv'\n",
    "fromGoogle = pd.read_csv(link)\n",
    "\n",
    "# here it is:\n",
    "fromGoogle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromGoogle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "-----\n",
    "\n",
    "<a id='part3'></a>\n",
    "\n",
    "## Collecting data from APIs\n",
    "\n",
    "There are organizations, public and private, that have an open data policy that allows people to access their repositories dynamically. You can get that data in CSV format if available, but the data is always in  XML or JSON format, which are containers that store data in an *associative array* structure. Python's dictionaries are very useful in these situations, as they can keep the NOSQL structure better than data frames. Let me get the data about 9-1-1 Police reponses from Seattle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sodapy\n",
    "\n",
    "# make sure to install these packages before running:\n",
    "# pip install pandas\n",
    "# pip install sodapy\n",
    "\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "client = Socrata(\"data.seattle.gov\", None)\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "# client = Socrata(data.seattle.gov,\n",
    "#                  MyAppToken,\n",
    "#                  username=\"user@example.com\",\n",
    "#                  password=\"AFakePassword\")\n",
    "\n",
    "# First 2000 results, returned as JSON from API / converted to Python list of\n",
    "# dictionaries by sodapy.\n",
    "results = client.get(\"kzjm-xkqj\", limit=2000)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "results_df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to page beginning](#beginning)\n",
    "\n",
    "_____\n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "## Collecting data by scraping\n",
    "\n",
    "We are going to get the data from a table from this [wikipage](https://en.wikipedia.org/wiki/List_of_freedom_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show beautifulsoup4 html5lib lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Location \n",
    "wikilink = \"https://en.wikipedia.org/wiki/List_of_freedom_indices\" \n",
    "\n",
    "wikiTables1=pd.read_html(wikilink)\n",
    "wikiTables2=pd.read_html(wikilink,attrs={'class':'wikitable sortable'})\n",
    "wikiTables3=pd.read_html(wikilink,match=\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many are there?\n",
    "len(wikiTables1),len(wikiTables2),len(wikiTables3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2_bs=pd.read_html(wikilink,flavor='bs4',\n",
    "                            attrs={'class':'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2_bs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTables2_bs[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freedomDF=wikiTables2_bs[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
